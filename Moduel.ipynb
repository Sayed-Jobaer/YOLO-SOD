{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCFEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCFEM(nn.Module):\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True:  \n",
    "        super(SCFEM, self).__init__()\n",
    "\n",
    "        #Apply padding to dilated convolutions to keep output size consistent\n",
    "        self.dilated_conv1 = nn.Conv2d(c1, c2, kernel_size=3, dilation=1, padding=1)\n",
    "        self.dilated_conv3 = nn.Conv2d(c1, c2, kernel_size=3, dilation=3, padding=3)\n",
    "        self.dilated_conv5 = nn.Conv2d(c1, c2, kernel_size=3, dilation=5, padding=5)\n",
    "        self.dilated_conv7 = nn.Conv2d(c1, c2, kernel_size=3, dilation=7, padding=7)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(c2 * 4)  # Update to c2 * 4\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 1x1 convolution to match the number of channels for the shortcut connection\n",
    "        self.conv1x1_shortcut = nn.Conv2d(c1, c2 * 4, kernel_size=1)\n",
    "\n",
    "        # CBL layers for the final output\n",
    "        self.conv_final1 = nn.Conv2d(c2 * 4, c2, kernel_size=1)\n",
    "        self.batch_norm_final1 = nn.BatchNorm2d(c2)  # Update to c2\n",
    "        self.leaky_relu1 = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.dilated_conv1(x)\n",
    "        out2 = self.dilated_conv3(x)\n",
    "        out3 = self.dilated_conv5(x)\n",
    "        out4 = self.dilated_conv7(x)\n",
    "\n",
    "        shortcut = self.conv1x1_shortcut(x)  # 1x1 convolution for shortcut connection\n",
    "        shortcut = F.interpolate(shortcut, size=(out1.size(2), out1.size(3)), mode='bilinear', align_corners=False)\n",
    "\n",
    "        concat_input = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        output = concat_input + shortcut\n",
    "        output = self.batch_norm(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        # Applying CBL to the concatenated output\n",
    "        output = self.conv_final1(output)\n",
    "        output = self.batch_norm_final1(output)\n",
    "        output = self.leaky_relu1(output)\n",
    "\n",
    "        # Upsampling the output to the original size\n",
    "        output = F.interpolate(output, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAFFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAFFM(nn.Module):\n",
    "    def __init__(self, c1, c2, k=5):\n",
    "        super(SAFFMModule, self).__init__()\n",
    "\n",
    "        # 1x1 Convolution to reduce channels and apply Batch Normalization\n",
    "        self.conv1x1 = nn.Sequential(\n",
    "            nn.Conv2d(c1, c2, kernel_size=1),\n",
    "            nn.BatchNorm2d(c2),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "\n",
    "        # Max Pooling layers with different kernel sizes\n",
    "        self.maxpool_5x5 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k//2)\n",
    "        self.maxpool_9x9 = nn.MaxPool2d(kernel_size=k*2, stride=1, padding=k)\n",
    "        self.maxpool_13x13 = nn.MaxPool2d(kernel_size=k*3, stride=1, padding=k*2)\n",
    "\n",
    "        # 1x1 Convolution to adjust channels after concatenation\n",
    "        self.concat_conv1 = nn.Conv2d(c2 * 4, c2, kernel_size=1)\n",
    "        self.concat_conv2 = nn.Conv2d(c2 * 2, c2, kernel_size=1)\n",
    "\n",
    "        # Final 1x1 Convolution to get 1024 output channels\n",
    "        self.final_conv = nn.Conv2d(c2, 1024, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reduce channels and apply Batch Normalization\n",
    "        x = self.conv1x1(x)\n",
    "\n",
    "        # Max Pooling layers\n",
    "        pool_5x5 = self.maxpool_5x5(x)\n",
    "        pool_9x9 = self.maxpool_9x9(x)\n",
    "        pool_13x13 = self.maxpool_13x13(x)\n",
    "\n",
    "        # Concatenate all the pooling outputs\n",
    "        concat_output = torch.cat([x, pool_5x5, pool_9x9, pool_13x13], dim=1)\n",
    "\n",
    "        # Apply 1x1 Convolution to reduce channels\n",
    "        concat_output = self.concat_conv1(concat_output)\n",
    "\n",
    "        # Shortcut connection\n",
    "        shortcut = self.conv1x1(x)\n",
    "\n",
    "        # Concatenate shortcut connection to the current Concatenation layer\n",
    "        concat_output = torch.cat([concat_output, shortcut], dim=1)\n",
    "\n",
    "        # Apply another 1x1 Convolution to reduce channels to 1024\n",
    "        concat_output = self.concat_conv2(concat_output)\n",
    "\n",
    "        # Apply final 1x1 Convolution to get 1024 output channels\n",
    "        output = self.final_conv(concat_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINSNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BINOBlock(nn.Module):\n",
    "    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):\n",
    "        super(BINOBlock, self).__init__()\n",
    "\n",
    "        # Inside BINO Block\n",
    "        self.conv1x1 = nn.Conv2d(c1, c2, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1x1 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # Spatially Separate Convolution (3x3 and 5x5)\n",
    "        self.conv3x3 = nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5x5 = nn.Conv2d(c2, c2, kernel_size=5, stride=1, padding=2)\n",
    "        self.batch_norm3x3_5x5 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # Up-sampling to Spatially Separate Convolution (5x5 and 7x7)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # Spatially Separate Convolution (5x5 and 7x7)\n",
    "        self.conv5x5_upsampled = nn.Conv2d(c2, c2, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv7x7_upsampled = nn.Conv2d(c2, c2, kernel_size=7, stride=1, padding=3)\n",
    "        self.batch_norm5x5_7x7 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # Up-sampling to 3x3\n",
    "        self.upsample_3x3 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # 1x1 Convolution followed by Activation Function (Leaky ReLU)\n",
    "        self.conv1x1_leaky_relu = nn.Conv2d(c2, c2, kernel_size=1, stride=1, padding=0)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.batch_norm1x1(x)\n",
    "\n",
    "        # Spatially Separate Convolution (3x3 and 5x5)\n",
    "        x3x3 = self.conv3x3(x)\n",
    "        x5x5 = self.conv5x5(x)\n",
    "        x = torch.cat([x3x3, x5x5], dim=1)\n",
    "        x = self.batch_norm3x3_5x5(x)\n",
    "\n",
    "        # Up-sampling to Spatially Separate Convolution (5x5 and 7x7)\n",
    "        x = self.upsample(x)\n",
    "        x5x5_upsampled = self.conv5x5_upsampled(x)\n",
    "        x7x7_upsampled = self.conv7x7_upsampled(x)\n",
    "        x = torch.cat([x5x5_upsampled, x7x7_upsampled], dim=1)\n",
    "        x = self.batch_norm5x5_7x7(x)\n",
    "\n",
    "        # Up-sampling to 3x3\n",
    "        x = self.upsample_3x3(x)\n",
    "\n",
    "        # 1x1 Convolution followed by Activation Function (Leaky ReLU)\n",
    "        x = self.conv1x1_leaky_relu(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BINSNet(nn.Module):\n",
    "    # BINSNet with additional parameters\n",
    "    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):\n",
    "        super(BINSNet, self).__init__()\n",
    "\n",
    "        # 1x1 Convolution followed by Batch Normalization\n",
    "        self.conv1x1_1 = nn.Conv2d(c1, c2, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # 3x3 Convolution followed by Batch Normalization\n",
    "        self.conv3x3 = nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # BINO Block\n",
    "        self.bino_block = BINOBlock(c2, c2)\n",
    "\n",
    "        # 3x3 Convolution followed by Batch Normalization\n",
    "        self.conv3x3_2 = nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm3_2 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # 1x1 Convolution\n",
    "        self.conv1x1_2 = nn.Conv2d(c2, c2, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        # Additional 3x3 Convolution with Batch Normalization\n",
    "        self.additional_conv3x3 = nn.Conv2d(c2 * 2, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.additional_batch_norm3 = nn.BatchNorm2d(c2)\n",
    "\n",
    "    def forward(self, x, prev_module_output):\n",
    "        # 1x1 Convolution followed by Batch Normalization\n",
    "        x = self.conv1x1_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "\n",
    "        # 3x3 Convolution followed by Batch Normalization\n",
    "        x = self.conv3x3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "\n",
    "        # BINO Block\n",
    "        bino_output = self.bino_block(x)\n",
    "\n",
    "        # 3x3 Convolution followed by Batch Normalization\n",
    "        x = self.conv3x3_2(bino_output)\n",
    "        x = self.batch_norm3_2(x)\n",
    "\n",
    "        # Concatenation\n",
    "        x = torch.cat([bino_output, x, prev_module_output], dim=1)\n",
    "\n",
    "        # Additional 3x3 Convolution with Batch Normalization\n",
    "        x = self.additional_conv3x3(x)\n",
    "        x = self.additional_batch_norm3(x)\n",
    "\n",
    "        # 1x1 Convolution\n",
    "        x = self.conv1x1_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBINSNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBINSNet(nn.Module):\n",
    "    # DBINSNet with additional parameters\n",
    "    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):\n",
    "        super(DBINSNet, self).__init__()\n",
    "\n",
    "        # 1x1 Convolution followed by Batch Normalization\n",
    "        self.conv1x1_1 = nn.Conv2d(c1, c2, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # BINO Blocks (Repeat 3 times)\n",
    "        self.dbino_block1 = BINOBlock(c2, c2)\n",
    "        self.dbino_block2 = BINOBlock(c2, c2)\n",
    "        self.dbino_block3 = BINOBlock(c2, c2)\n",
    "\n",
    "        # 1x1 Convolution followed by Batch Normalization\n",
    "        self.conv1x1_2 = nn.Conv2d(c2, c2, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut_conv1x1 = nn.Conv2d(c1, c2, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm_shortcut = nn.BatchNorm2d(c2)\n",
    "\n",
    "        # Additional 1x1 Convolution\n",
    "        self.additional_conv1x1 = nn.Conv2d(c2, c2, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1x1 Convolution followed by Batch Normalization\n",
    "        x = self.conv1x1_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "\n",
    "        # BINO Blocks\n",
    "        bino_output1 = self.bino_block1(x)\n",
    "        bino_output2 = self.bino_block2(bino_output1)\n",
    "        bino_output3 = self.bino_block3(bino_output2)\n",
    "\n",
    "        # Concatenation\n",
    "        x = torch.cat([bino_output1, bino_output2, bino_output3, x], dim=1)\n",
    "        \n",
    "        # 1x1 Convolution followed by Batch Normalization\n",
    "        x = self.conv1x1_2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "\n",
    "        # Shortcut connection\n",
    "        shortcut = self.shortcut_conv1x1(x)\n",
    "        shortcut = self.batch_norm_shortcut(shortcut)\n",
    "\n",
    "        # Additional 1x1 Convolution\n",
    "        x = self.additional_conv1x1(x)\n",
    "\n",
    "        return x + shortcut  # Shortcut connection (Residual connection)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
